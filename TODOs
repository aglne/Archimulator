Reading list:
    Predicting Inter-Thread Cache Contention on a Chip Multi-Processor Architecture
    Prefetching with Helper Threads for Loosely Coupled Multiprocessor Systems

Hints from Cache showndown: the good, bad and ugly:
    Useful prefetches are those that are actually accessed, while harmful prefetches are those that are never accessed
    and are a direct cause of misses to cache lines that were displaced by that prefetch line. Finally, useless
    prefetches are those that are never accessed.

    At any point in execution, the union of the non-prefetched tags in the cache and the evict tags in the ET give the state of of cache as if prefetching had never occurred.

TODOs:
    L2: 512K, 1M, 2M, 3M
    Benchmarks: mst, em3d, mcf

---------------------

Archimulator on the cloud:
    1. get CPU usage on Guest
    2. get Memory usage on Guest

TODOs:
    1. viewing program output.. from UI
    2. auto-tuning parameters of the HT scheme

    *. a. late HT requests -> Spawn H/W thread to prefetch for HT
       b. bad HT requests -> Pause HT, resume HT in the next phase (128K insts in MT?)
       c. good HT requests -> increase/decrease confidence counter value

